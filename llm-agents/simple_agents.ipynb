{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85f8cb7e",
   "metadata": {},
   "source": [
    "# LLM Agents Walkthrough\n",
    "\n",
    "This is a  tutorial on building LLM agents! This notebook will take you through a building basic agent concepts to sophisticated multi-agent systems.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Basic Agent Architecture**: Understanding the core components of LLM agents\n",
    "2. **Specialized Agents**: Creating agents with specific capabilities (fact extraction, sentiment analysis)\n",
    "3. **Tool Integration**: Enabling agents to use external tools (web search, Wikipedia)\n",
    "4. **Agent Orchestration**: Coordinating multiple agents to work together\n",
    "5. **Real-world Applications**: Practical examples and best practices\n",
    "\n",
    "## Prerequisites\n",
    "- Google Gemini API key (set in GEMINI_API_KEY environment variable)\n",
    "- Brave Search API key for web search functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0795f409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sajjad/miniconda3/envs/titan/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from typing import Dict\n",
    "from dataclasses import dataclass\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pp\n",
    "import requests\n",
    "import wikipediaapi\n",
    "import time\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7bc696",
   "metadata": {},
   "source": [
    "## Configuring the LLM\n",
    "\n",
    "Now let's configure our Large Language Model (Google Gemini). This is the brain of our agents.\n",
    "\n",
    "**Important**: Make sure you have your `GEMINI_API_KEY` set in your environment variables or `.env` file. You can get a free API key from [Google AI Studio](https://makersuite.google.com/app/apikey).\n",
    "\n",
    "The configuration below will:\n",
    "- Load the API key from environment variables\n",
    "- Initialize the Gemini model (we're using gemini-2.0-flash for its speed and capability)\n",
    "- Confirm successful setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a514d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini model configured successfully\n"
     ]
    }
   ],
   "source": [
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "if not api_key:\n",
    "    print(\"GEMINI_API_KEY environment variable is not set\")\n",
    "else:\n",
    "    genai.configure(api_key=api_key)\n",
    "    gemini = genai.GenerativeModel('gemini-2.0-flash')\n",
    "    print(\"Gemini model configured successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a853028",
   "metadata": {},
   "source": [
    "## Testing Basic LLM Interaction\n",
    "\n",
    "Before we build agents, let's test our basic LLM setup with a simple query. This will help us understand the foundation upon which we'll build our agent system.\n",
    "\n",
    "We'll ask about AI trends to see how the model responds to a contemporary topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e285987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the trends in AI impact on job markets in 2025?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7776c961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down the projected AI impact on job markets in 2025, focusing on key trends and areas of significant change.  Keep in mind that these are predictions, and the actual impact will depend on various factors like the pace of AI development, adoption rates, and policy decisions.\n",
      "\n",
      "**Overall Themes:**\n",
      "\n",
      "*   **Automation and Augmentation:**  The central theme remains automation of routine tasks, but increasingly, AI is seen as augmenting human capabilities rather than solely replacing them. This means AI handles repetitive tasks, freeing up humans for more creative, strategic, and complex work.\n",
      "*   **Job Displacement and Creation:**  AI will displace some jobs, particularly those involving repetitive manual or cognitive tasks. However, it will also create new jobs, especially in fields related to AI development, implementation, and maintenance, as well as in areas that require uniquely human skills. The net effect on overall employment is still debated, with some studies predicting a net increase in jobs and others suggesting a potential net loss, at least in the short term.\n",
      "*   **Skill Shift:** The skills required for many jobs will change.  Technical skills related to AI will be in high demand, but so will soft skills like critical thinking, creativity, communication, emotional intelligence, and adaptability.  Upskilling and reskilling initiatives will be crucial.\n",
      "*   **Increased Productivity:** AI is expected to boost productivity across many industries by automating processes, improving decision-making, and enabling personalized experiences.\n",
      "\n",
      "**Key Trends in Specific Sectors/Job Roles:**\n",
      "\n",
      "1.  **Customer Service:**\n",
      "\n",
      "    *   **Trend:** Increased use of AI-powered chatbots and virtual assistants for handling routine inquiries, resolving simple issues, and providing personalized recommendations.\n",
      "    *   **Impact:** Reduction in the number of traditional customer service representatives handling basic tasks.  Shift towards roles requiring empathy, problem-solving skills for complex issues, and the ability to manage and train AI systems.\n",
      "    *   **Jobs at Risk:** Basic call center jobs, order takers, and complaint handlers.\n",
      "    *   **Jobs Emerging/Evolving:** AI chatbot trainers, customer experience designers, and escalation specialists.\n",
      "\n",
      "2.  **Data Analysis and Business Intelligence:**\n",
      "\n",
      "    *   **Trend:** AI automates data collection, cleaning, and initial analysis. Machine learning algorithms identify patterns and insights more quickly and efficiently than humans.\n",
      "    *   **Impact:** Data analysts will need to focus more on interpreting AI-generated insights, communicating them effectively to stakeholders, and developing strategies based on those insights.\n",
      "    *   **Jobs at Risk:** Data entry clerks, basic data analysts performing repetitive tasks.\n",
      "    *   **Jobs Emerging/Evolving:** AI-driven data strategists, data storytellers, and AI model explainability experts.\n",
      "\n",
      "3.  **Manufacturing and Logistics:**\n",
      "\n",
      "    *   **Trend:** Increased automation through robotics, AI-powered predictive maintenance, and optimization of supply chains.\n",
      "    *   **Impact:** Greater efficiency, reduced costs, and improved quality control.  Shift towards roles requiring skills in robotics, AI, and data analysis.\n",
      "    *   **Jobs at Risk:** Assembly line workers performing repetitive tasks, warehouse workers involved in manual sorting and packing.\n",
      "    *   **Jobs Emerging/Evolving:** Robot technicians, AI-powered supply chain managers, and predictive maintenance specialists.\n",
      "\n",
      "4.  **Transportation:**\n",
      "\n",
      "    *   **Trend:** Development and deployment of autonomous vehicles (trucks, cars, drones).\n",
      "    *   **Impact:** Potential displacement of drivers, but also creation of new jobs in autonomous vehicle maintenance, software development, and infrastructure management.  Regulatory hurdles and public acceptance will be key factors.\n",
      "    *   **Jobs at Risk:** Truck drivers, taxi drivers, delivery drivers (potentially, depending on regulations).\n",
      "    *   **Jobs Emerging/Evolving:** Autonomous vehicle mechanics, AI-powered traffic management specialists, drone operators.\n",
      "\n",
      "5.  **Healthcare:**\n",
      "\n",
      "    *   **Trend:** AI assists with diagnosis, treatment planning, drug discovery, and personalized medicine.\n",
      "    *   **Impact:** Improved accuracy, faster diagnosis, and more effective treatments.  Doctors and nurses will need to collaborate with AI systems and interpret AI-generated insights.\n",
      "    *   **Jobs at Risk:** Certain diagnostic roles currently performed by human specialists could be impacted.\n",
      "    *   **Jobs Emerging/Evolving:** AI-assisted diagnostic specialists, telehealth specialists, AI-powered drug discovery researchers.\n",
      "\n",
      "6.  **Finance:**\n",
      "\n",
      "    *   **Trend:** AI automates fraud detection, risk assessment, and algorithmic trading.\n",
      "    *   **Impact:** Increased efficiency, reduced costs, and improved accuracy.  Financial professionals will need to understand AI algorithms and use them to make better decisions.\n",
      "    *   **Jobs at Risk:** Financial analysts performing routine tasks, loan officers evaluating basic applications.\n",
      "    *   **Jobs Emerging/Evolving:** AI-powered risk management specialists, algorithmic trading strategists, and financial data scientists.\n",
      "\n",
      "7.  **Creative Industries:**\n",
      "\n",
      "    *   **Trend:** AI tools are being developed for content creation (writing, music, art).\n",
      "    *   **Impact:** AI can assist with generating ideas, creating drafts, and automating repetitive tasks, but human creativity and emotional intelligence will remain crucial.\n",
      "    *   **Jobs at Risk:** Some entry-level content creation roles may be impacted.\n",
      "    *   **Jobs Emerging/Evolving:** AI-assisted content creators, prompt engineers, and creative AI trainers.\n",
      "\n",
      "8.  **Education:**\n",
      "\n",
      "    *   **Trend:** AI is used for personalized learning, automated grading, and administrative tasks.\n",
      "    *   **Impact:** Teachers can focus more on individual student needs and provide personalized instruction.\n",
      "    *   **Jobs at Risk:** Some administrative roles could be automated.\n",
      "    *   **Jobs Emerging/Evolving:** AI-assisted learning designers, personalized learning specialists, and AI-powered education tool developers.\n",
      "\n",
      "**Critical Skills for 2025:**\n",
      "\n",
      "*   **Technical Skills:**\n",
      "    *   AI and Machine Learning\n",
      "    *   Data Science and Analytics\n",
      "    *   Cloud Computing\n",
      "    *   Cybersecurity\n",
      "    *   Software Development (especially with AI focus)\n",
      "    *   Robotics\n",
      "*   **Soft Skills:**\n",
      "    *   Critical Thinking and Problem-Solving\n",
      "    *   Creativity and Innovation\n",
      "    *   Communication and Collaboration\n",
      "    *   Emotional Intelligence and Empathy\n",
      "    *   Adaptability and Lifelong Learning\n",
      "    *   Leadership and Management (especially in AI-driven environments)\n",
      "\n",
      "**Factors Influencing the Impact:**\n",
      "\n",
      "*   **Pace of AI Development:** The speed at which AI technology advances will significantly affect the pace of job displacement and creation.\n",
      "*   **Adoption Rates:** How quickly businesses and organizations adopt AI solutions will determine the scale of the impact.\n",
      "*   **Government Policies:** Policies related to education, training, social safety nets, and AI regulation will play a crucial role in shaping the labor market.\n",
      "*   **Ethical Considerations:** Concerns about bias, fairness, and transparency in AI systems will need to be addressed to ensure equitable outcomes.\n",
      "*   **Economic Conditions:** The overall health of the economy will influence the demand for labor and the ability of displaced workers to find new jobs.\n",
      "\n",
      "**In Summary:**\n",
      "\n",
      "The AI revolution is not just about automation; it's about a fundamental shift in the way we work.  In 2025, we can expect to see AI increasingly integrated into various industries, automating tasks, augmenting human capabilities, and creating new opportunities.  The key to success in this new landscape will be adaptability, a commitment to lifelong learning, and the development of both technical and soft skills that complement AI.  Being able to understand, use, and manage AI systems, as well as collaborate effectively with them, will be essential for thriving in the job market of the future.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = gemini.generate_content(query)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c764d7",
   "metadata": {},
   "source": [
    "## Building Our First Agent: The BaseAgent Class\n",
    "\n",
    "Now we'll create our first agent! An **agent** is essentially a wrapper around an LLM that gives it specific instructions and behavior.\n",
    "\n",
    "### What Makes This an Agent?\n",
    "\n",
    "1. **Identity**: Each agent has a name and specific role\n",
    "2. **Instructions**: Pre-defined system prompts that shape behavior\n",
    "3. **Consistent Interface**: A standard way to process queries\n",
    "4. **Specialization**: Each agent can be tailored for specific tasks\n",
    "\n",
    "The `BaseAgent` class will serve as the foundation for all our specialized agents. It demonstrates the core pattern: **LLM + Instructions = Agent**.\n",
    "\n",
    "### 🏗️ Basic Agent Architecture\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────┐\n",
    "│                BaseAgent                │\n",
    "├─────────────────────────────────────────┤\n",
    "│  Properties:                            │\n",
    "│  • name: str                            │\n",
    "│  • instructions: str                    │\n",
    "├─────────────────────────────────────────┤\n",
    "│  Methods:                               │\n",
    "│  • process(query) → response            │\n",
    "└─────────────────────────────────────────┘\n",
    "                    │\n",
    "                    ▼\n",
    "┌─────────────────────────────────────────┐\n",
    "│              Query Flow                 │\n",
    "├─────────────────────────────────────────┤\n",
    "│  User Query                             │\n",
    "│       │                                 │\n",
    "│       ▼                                 │\n",
    "│  Instructions + Query                   │\n",
    "│       │                                 │\n",
    "│       ▼                                 │\n",
    "│  LLM (Gemini)                           │\n",
    "│       │                                 │\n",
    "│       ▼                                 │\n",
    "│  Processed Response                     │\n",
    "└─────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88cf6489",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAgent:\n",
    "    \"\"\"Simple base agent that wraps LLM calls with specific instructions\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, instructions: str):\n",
    "        self.name = name\n",
    "        self.instructions = instructions\n",
    "    \n",
    "    def process(self, query: str) -> str:\n",
    "        \"\"\"Process query with agent-specific instructions\"\"\"\n",
    "        full_prompt = f\"{self.instructions}\\n\\nQuery: {query}\"\n",
    "        return gemini.generate_content(full_prompt).text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fc48a4",
   "metadata": {},
   "source": [
    "## Creating Specialized Agents\n",
    "\n",
    "Now let's create our first specialized agents! Each agent will have different instructions that make it excel at specific tasks:\n",
    "\n",
    "- **FactExtractor**: Focuses on extracting factual information and statistics\n",
    "- **SentimentAnalyzer**: Specializes in analyzing emotions and sentiment\n",
    "- **Summarizer**: Excels at creating concise summaries\n",
    "\n",
    "This demonstrates how the same LLM can be given different \"personalities\" and capabilities through prompt engineering.\n",
    "\n",
    "### 🎭 Specialized Agent Architecture\n",
    "\n",
    "```\n",
    "                    BaseAgent (Foundation)\n",
    "                          │\n",
    "        ┌─────────────────┼─────────────────┐\n",
    "        │                 │                 │\n",
    "        ▼                 ▼                 ▼\n",
    "┌──────────────┐ ┌─────────────────┐    ┌──────────────┐\n",
    "│FactExtractor │ │SentimentAnalyzer│    │ Summarizer   │\n",
    "├──────────────┤ ├─────────────────┤    ├──────────────┤\n",
    "│Instructions: │ │Instructions:    │    │Instructions: │\n",
    "│\"Extract only │ │\"Analyze         │    │\"Generate     │\n",
    "│ factual info │ │ sentiment       │    │ concise      │\n",
    "│ and stats\"   │ │ and emotion\"    │    │ summary\"     │\n",
    "└──────────────┘ └─────────────────┘    └──────────────┘\n",
    "        │                 │                 │\n",
    "        ▼                 ▼                 ▼\n",
    "┌──────────────┐ ┌──────────────┐ ┌──────────────┐\n",
    "│   Output:    │ │   Output:    │ │   Output:    │\n",
    "│ • Facts      │ │ • Positive/  │ │ • Key Points │\n",
    "│ • Statistics │ │   Negative   │ │ • Summary    │\n",
    "│ • Numbers    │ │ • Emotions   │ │ • Overview   │\n",
    "└──────────────┘ └──────────────┘ └──────────────┘\n",
    "\n",
    "Same Input → Different Processing → Different Outputs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f22c8b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_extractor = BaseAgent(\"FactExtractor\", \"Extract only factual information and statistics.\")\n",
    "sentiment_analyzer = BaseAgent(\"SentimentAnalyzer\", \"Analyze sentiment and emotional tone.\")\n",
    "summarizer = BaseAgent(\"Summarizer\", \"Generate concise summary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a66e27a",
   "metadata": {},
   "source": [
    "## 6. Testing Our Specialized Agents\n",
    "\n",
    "Let's test each of our specialized agents with the same query to see how their different instructions affect their responses. Notice how each agent will focus on different aspects of the same information!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ca99eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facts: Without specific sources or a date range, it's impossible to provide precise factual information and statistics about AI's impact on job markets in 2025.  Predictions are not factual information. However, I can provide examples of the *type* of factual information and statistics that *would* be relevant if available from a reliable source with a specific date range:\n",
      "\n",
      "*   **Specific Job Displacement Numbers:** \"A study by [Organization Name] projects that AI will displace [Number] jobs in [Industry] by 2025.\"\n",
      "*   **Job Creation Numbers:** \"[Source] estimates that AI will create [Number] new jobs in [Field] by 2025.\"\n",
      "*   **Skills Gap Statistics:** \"Research indicates that [Percentage]% of the workforce will require reskilling in [Specific Skill] to remain relevant in the AI-driven economy by 2025.\"\n",
      "*   **Industry-Specific Impacts:** \"In the [Industry] sector, AI is expected to automate [Percentage]% of tasks currently performed by [Job Title] by 2025, according to [Source].\"\n",
      "*   **Geographic Variations:** \"AI's impact on job displacement is projected to be highest in [Region] by 2025, with an estimated loss of [Number] jobs, while [Other Region] is expected to see a net gain of [Number] jobs due to AI adoption, as reported by [Source].\"\n",
      "*   **Wage Changes:** \"A report by [Organization] forecasts that wages for [Job Title] requiring AI expertise will increase by [Percentage]% by 2025, while wages for [Job Title] vulnerable to automation may decline by [Percentage]%.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Facts: {fact_extractor.process(query)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78246013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: This query is **neutral** in sentiment and tone.\n",
      "\n",
      "*   **Sentiment:** It expresses no positive or negative feelings towards AI or its impact. It simply seeks information.\n",
      "*   **Emotional Tone:** It's objective and analytical. It doesn't convey excitement, fear, hope, or any other emotion. It's purely informational.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sentiment: {sentiment_analyzer.process(query)}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "809edf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: In 2025, AI is expected to significantly reshape job markets, leading to both job displacement and creation. **Automation will displace roles in routine and repetitive tasks, particularly in data entry, customer service, and manufacturing.** Simultaneously, **demand will surge for AI-related roles such as AI specialists, data scientists, and AI engineers.** Upskilling and reskilling initiatives will be crucial to bridge the skills gap and prepare workers for the evolving demands of an AI-driven economy. Overall, the impact will be uneven, with some sectors and skill sets experiencing more disruption than others.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Summary: {summarizer.process(query)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819198a1",
   "metadata": {},
   "source": [
    "## 7. Structured Output: JSON Processing Utility\n",
    "\n",
    "As we build more sophisticated agents, we'll need them to return structured data instead of just text. This utility function helps us:\n",
    "\n",
    "1. **Extract JSON from LLM responses**: LLMs often wrap JSON in markdown code blocks\n",
    "2. **Handle parsing errors gracefully**: Provides clear error messages when JSON is malformed\n",
    "3. **Enable structured agent communication**: Allows agents to return dictionaries instead of just strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4a97da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_parse_json(text_response):\n",
    "    \"\"\"\n",
    "    Extracts a JSON string from a text that might be wrapped in Markdown code blocks\n",
    "    (e.g., ```json...```) and then parses it into a Python dictionary.\n",
    "\n",
    "    Args:\n",
    "        text_response (str): The raw string response from the AI model.\n",
    "\n",
    "    Returns:\n",
    "        dict: The parsed JSON object.\n",
    "        None: If no valid JSON is found or if parsing fails.\n",
    "    \"\"\"\n",
    "    # Regex to find content inside ```json ... ``` or just ``` ... ```\n",
    "    # It tries to find '```json' first, then falls back to '```'\n",
    "    json_match = re.search(r'```(?:json)?(?s)(.*?)```', text_response)\n",
    "\n",
    "    if json_match:\n",
    "        # Extract the content within the backticks and strip any leading/trailing whitespace\n",
    "        json_string = json_match.group(1).strip()\n",
    "    else:\n",
    "        # If no markdown block found, assume the entire response is the JSON string\n",
    "        json_string = text_response.strip()\n",
    "\n",
    "    try:\n",
    "        # Attempt to parse the cleaned string as JSON\n",
    "        parsed_data = json.loads(json_string)\n",
    "        return parsed_data\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        print(f\"Problematic JSON string: '{json_string}'\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during JSON processing: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625e7ffc",
   "metadata": {},
   "source": [
    "## Advanced Agent Architecture: Structured Output Agents\n",
    "\n",
    "Now let's build more sophisticated agents that return structured data! This `FactExtractorAgent` demonstrates several advanced concepts:\n",
    "\n",
    "### Key Improvements:\n",
    "1. **Structured Output**: Returns JSON with organized facts, entities, and statistics\n",
    "2. **Detailed Instructions**: More specific prompts that guide the LLM to produce consistent output\n",
    "3. **Error Handling**: Uses our JSON parsing utility to handle malformed responses\n",
    "4. **Specialized Methods**: Different methods for different types of operations\n",
    "\n",
    "This pattern makes agents more reliable and their outputs more useful for downstream processing.\n",
    "\n",
    "### 🏗️ Advanced Agent Architecture\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────┐\n",
    "│                 FactExtractorAgent                      │\n",
    "├─────────────────────────────────────────────────────────┤\n",
    "│  Input: Raw Text                                        │\n",
    "│       │                                                 │\n",
    "│       ▼                                                 │\n",
    "│  ┌─────────────────────────────────────────────────┐    │\n",
    "│  │        Detailed JSON Instructions               │    │\n",
    "│  │  • Must return JSON format                      │    │\n",
    "│  │  • Specific keys required                       │    │\n",
    "│  │  • Example format provided                      │    │\n",
    "│  └─────────────────────────────────────────────────┘    │\n",
    "│       │                                                 │\n",
    "│       ▼                                                 │\n",
    "│  ┌─────────────────────────────────────────────────┐    │\n",
    "│  │              LLM Processing                     │    │\n",
    "│  └─────────────────────────────────────────────────┘    │\n",
    "│       │                                                 │\n",
    "│       ▼                                                 │\n",
    "│  ┌─────────────────────────────────────────────────┐    │\n",
    "│  │           JSON Parser                           │    │\n",
    "│  │  • Extract from markdown blocks                 │    │\n",
    "│  │  • Handle parsing errors                        │    │\n",
    "│  │  • Return structured dict                       │    │\n",
    "│  └─────────────────────────────────────────────────┘    │\n",
    "│       │                                                 │\n",
    "│       ▼                                                 │\n",
    "│  ┌─────────────────────────────────────────────────┐    │\n",
    "│  │          Structured Output                      │    │\n",
    "│  │  {                                              │    │\n",
    "│  │    \"facts\": [\"fact1\", \"fact2\"],                 │    │\n",
    "│  │    \"entities\": [\"entity1\", \"entity2\"],          │    │\n",
    "│  │    \"statistics\": [\"40%\", \"2024\"],               │    │\n",
    "│  │    \"summary\": \"Brief overview\",                 │    │\n",
    "│  │    \"key_points\": [\"point1\", \"point2\"]           │    │\n",
    "│  │  }                                              │    │\n",
    "│  └─────────────────────────────────────────────────┘    │\n",
    "└─────────────────────────────────────────────────────────┘\n",
    "\n",
    "Basic Agent → Advanced Agent with Structured Output\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5209fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactExtractorAgent(BaseAgent):\n",
    "    \"\"\"Agent specialized in extracting facts and statistics\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"FactExtractor\", \"Extract facts and statistics from text. Return structured data.\")\n",
    "    \n",
    "    def extract_facts(self, text: str) -> Dict:\n",
    "        \"\"\"Extract structured facts from text\"\"\"\n",
    "        prompt = (\n",
    "            f\"Extract all salient factual information from the following text: '{text}'. \"\n",
    "            \"Identify distinct factual statements, key entities mentioned, and provide a concise summary of the factual content. \"\n",
    "            \"Your response MUST be a JSON object containing ONLY the following keys: \"\n",
    "            \"'facts' (as a list of strings, each a distinct factual statement), \"\n",
    "            \"'entities' (as a list of relevant entities mentioned, e.g., people, organizations, dates, locations), \"\n",
    "            \"'statistics' (a list of numerical data or statistics extracted), \"\n",
    "            \"'summary' (a brief summary of the extracted facts), \"\n",
    "            \"'key_points' (a list of key points derived from the facts). \"\n",
    "            \"DO NOT include any additional text, explanations, or Markdown formatting (like ```json).\"\n",
    "            f\"\\n\\nExample desired format (values are illustrative): {{\"\n",
    "            f\"\\\"facts\\\": [\"\n",
    "            f\"    \\\"The Eiffel Tower is located in Paris, France.\\\",\"\n",
    "            f\"    \\\"It was completed in 1889.\\\",\"\n",
    "            f\"    \\\"Gustave Eiffel's company designed it.\\\"\"\n",
    "            f\"],\"\n",
    "            f\"\\\"entities\\\": [\\\"Eiffel Tower\\\", \\\"Paris\\\", \\\"France\\\", \\\"1889\\\", \\\"Gustave Eiffel\\\"],\"\n",
    "            f\"\\\"summary\\\": \\\"Key facts about the Eiffel Tower, including its location, completion date, and designer.\\\",\"\n",
    "            f\"}}\"\n",
    "        )\n",
    "        response = self.process(prompt)\n",
    "        return extract_and_parse_json(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ba20c2",
   "metadata": {},
   "source": [
    "### Advanced Sentiment Analysis Agent\n",
    "\n",
    "Similarly, here's our enhanced sentiment analyzer that returns structured sentiment analysis:\n",
    "\n",
    "**Features:**\n",
    "- **Confidence Scoring**: How certain the agent is about its analysis\n",
    "- **Tone Detection**: Identifies specific emotions beyond just positive/negative\n",
    "- **Justification**: Explains why it reached its conclusion\n",
    "- **Consistent Format**: Always returns the same JSON structure\n",
    "\n",
    "This makes sentiment analysis results much more actionable and interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38a2b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalyzerAgent(BaseAgent):\n",
    "    \"\"\"Agent specialized in sentiment analysis\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"SentimentAnalyzer\", \"Analyze sentiment and return positive/negative/neutral.\")\n",
    "    \n",
    "    def analyze_sentiment(self, text: str) -> Dict:\n",
    "        \"\"\"Analyze sentiment with confidence score\"\"\"\n",
    "        prompt = (\n",
    "            f\"Analyze the sentiment of the following text: '{text}'. \"\n",
    "            \"Return the primary sentiment as 'positive', 'negative', or 'neutral', \"\n",
    "            \"along with an overall confidence score. \"\n",
    "            \"Also, identify the specific emotional 'tone(s)' present (e.g., 'joy', 'anger', 'sadness', 'excitement') \"\n",
    "            \"and provide a 'justification' explaining why that sentiment was assigned, \"\n",
    "            \"citing specific parts of the text if possible. \"\n",
    "            \"Your response MUST be a JSON object containing ONLY the following keys: \"\n",
    "            \"'sentiment', 'confidence', 'tone' (as a list of strings), and 'justification'. \"\n",
    "            \"DO NOT include any additional text, explanations, or Markdown formatting (like ```json).\"\n",
    "            f\"\\n\\nExample desired format (values are illustrative): {{\"\n",
    "            f\"\\\"sentiment\\\": \\\"positive\\\", \"\n",
    "            f\"\\\"confidence\\\": 0.92, \"\n",
    "            f\"\\\"tone\\\": [\\\"joy\\\", \\\"excitement\\\"], \"\n",
    "            f\"\\\"justification\\\": \\\"The user expressed enthusiasm with phrases like 'absolutely loved it' and 'highly recommend'.\\\"\"\n",
    "            f\"}}\"\n",
    "        )\n",
    "        response = self.process(prompt)\n",
    "        return extract_and_parse_json(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ab71e3",
   "metadata": {},
   "source": [
    "## 9. Testing Advanced Agents\n",
    "\n",
    "Let's instantiate our advanced agents and test them with structured output. Notice how much more useful and organized the results are compared to our basic agents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e5375b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_agent = FactExtractorAgent()\n",
    "sentiment_agent = SentimentAnalyzerAgent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad020f5f",
   "metadata": {},
   "source": [
    "### Sample Text for Testing\n",
    "\n",
    "Let's use a sample text that contains both factual information and emotional content to test our agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13cf25d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Specialized extraction:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2547187/4008867761.py:15: DeprecationWarning: Flags not at the start of the expression '```(?:json)?(?s)(.*?' (truncated) but at position 12\n",
      "  json_match = re.search(r'```(?:json)?(?s)(.*?)```', text_response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Extracted Facts******\n",
      "{   'facts': ['AI adoption increased 40% in 2024.'],\n",
      "    'entities': ['AI', '2024'],\n",
      "    'statistics': ['40%'],\n",
      "    'summary': 'AI adoption grew by 40% in 2024.',\n",
      "    'key_points': ['Significant increase in AI adoption.']}\n",
      "\n",
      "*****Sentiment Analysis******\n",
      "{   'sentiment': 'positive',\n",
      "    'confidence': 0.75,\n",
      "    'tone': ['optimism', 'acceptance'],\n",
      "    'justification': \"The statement highlights a positive trend ('AI adoption \"\n",
      "                     \"increased 40%') and focuses on 'positive opportunities'. \"\n",
      "                     \"While it acknowledges the need for 'adaptation', the \"\n",
      "                     'overall framing leans towards a positive outlook.'}\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 Specialized extraction:\")\n",
    "sample_text = \"AI adoption increased 40% in 2024. This creates positive opportunities but requires adaptation.\"\n",
    "facts = fact_agent.extract_facts(sample_text)\n",
    "sentiment = sentiment_agent.analyze_sentiment(sample_text)\n",
    "print(f\"*****Extracted Facts******\")\n",
    "pp(facts, indent=4)\n",
    "print()\n",
    "print(f\"*****Sentiment Analysis******\")\n",
    "pp(sentiment, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fd825a",
   "metadata": {},
   "source": [
    "## Agent Coordination Patterns\n",
    "\n",
    "Now let's explore different ways to coordinate multiple agents. There are two main patterns:\n",
    "\n",
    "### 1. Independent (Parallel) Agents\n",
    "- All agents work on the same input simultaneously\n",
    "- Fast execution, no dependencies\n",
    "- Good for getting different perspectives on the same data\n",
    "\n",
    "### 2. Sequential (Pipeline) Agents  \n",
    "- Agents work in sequence, with each building on the previous\n",
    "- More sophisticated processing, but slower\n",
    "- Good for complex analysis where later steps depend on earlier results\n",
    "\n",
    "Let's implement both patterns and see the differences!\n",
    "\n",
    "### 🔄 Agent Coordination Architecture\n",
    "\n",
    "#### Pattern 1: Independent (Parallel) Processing\n",
    "```\n",
    "                    Input Text\n",
    "                         │\n",
    "        ┌────────────────┼────────────────┐\n",
    "        │                │                │\n",
    "        ▼                ▼                ▼\n",
    "┌──────────────┐ ┌─────────────────┐ ┌──────────────┐\n",
    "│ FactExtractor│ │SentimentAnalyzer│ │ Summarizer   │\n",
    "│              │ │                 │ │              │\n",
    "│   (Agent 1)  │ │   (Agent 2)     │ │   (Agent 3)  │\n",
    "└──────────────┘ └─────────────────┘ └──────────────┘\n",
    "        │                │                │\n",
    "        ▼                ▼                ▼\n",
    "┌──────────────┐ ┌──────────────┐ ┌──────────────┐\n",
    "│   Facts      │ │  Sentiment   │ │   Summary    │\n",
    "│   Output     │ │   Output     │ │   Output     │\n",
    "└──────────────┘ └──────────────┘ └──────────────┘\n",
    "        │                │                │\n",
    "        └────────────────┼────────────────┘\n",
    "                         ▼\n",
    "                 Combined Results\n",
    "```\n",
    "\n",
    "#### Pattern 2: Sequential (Pipeline) Processing\n",
    "```\n",
    "Input Text\n",
    "    │\n",
    "    ▼\n",
    "┌──────────────┐\n",
    "│ FactExtractor│  Step 1: Extract Facts\n",
    "│   (Agent 1)  │\n",
    "└──────────────┘\n",
    "    │\n",
    "    ▼ (Facts Output)\n",
    "┌──────────────┐\n",
    "│SentimentAnalyzer Step 2: Analyze Sentiment of Facts\n",
    "│   (Agent 2)  │\n",
    "└──────────────┘\n",
    "    │\n",
    "    ▼ (Facts + Sentiment)\n",
    "┌──────────────┐\n",
    "│ Summarizer   │  Step 3: Enhanced Summary with Context\n",
    "│   (Agent 3)  │\n",
    "└──────────────┘\n",
    "    │\n",
    "    ▼\n",
    "Enhanced Result (Each step builds on previous)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eae24a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_independent_agents(text: str):\n",
    "    print(\"Running agents in parallel...\")\n",
    "    \n",
    "    # All agents work on same input independently\n",
    "    facts = fact_agent.extract_facts(text)\n",
    "    sentiment = sentiment_agent.analyze_sentiment(text)\n",
    "    summary = summarizer.process(text)\n",
    "    \n",
    "    return {\n",
    "        \"facts\": facts,\n",
    "        \"sentiment\": sentiment,  \n",
    "        \"summary\": summary\n",
    "    }\n",
    "\n",
    "def run_sequential_agents(text: str):\n",
    "    print(\"Running agents sequentially...\")\n",
    "    \n",
    "    # Step 1: Extract facts first\n",
    "    facts = fact_agent.extract_facts(text)\n",
    "    print(f\"Step 1 - Facts extracted: {len(facts['statistics'])} statistics found\")\n",
    "    \n",
    "    # Step 2: Analyze sentiment of extracted facts specifically\n",
    "    facts_text = \" \".join(facts['key_points'])\n",
    "    sentiment = sentiment_agent.analyze_sentiment(facts_text)\n",
    "    print(f\"Step 2 - Sentiment of facts: {sentiment['sentiment']}\")\n",
    "    \n",
    "    # Step 3: Create summary using both facts and sentiment\n",
    "    enhanced_input = f\"Facts: {facts_text}. Sentiment: {sentiment['sentiment']}\"\n",
    "    summary = summarizer.process(enhanced_input)\n",
    "    print(f\"Step 3 - Enhanced summary created\")\n",
    "    \n",
    "    return {\n",
    "        \"facts\": facts,\n",
    "        \"sentiment\": sentiment,\n",
    "        \"enhanced_summary\": summary\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c66873",
   "metadata": {},
   "source": [
    "### Testing Sequential Agent Coordination\n",
    "\n",
    "Let's test our sequential agent pattern where each agent builds on the results of the previous one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6def2135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running agents sequentially...\n",
      "Step 1 - Facts extracted: 1 statistics found\n",
      "Step 2 - Sentiment of facts: neutral\n",
      "Step 3 - Enhanced summary created\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dependent_results = run_sequential_agents(sample_text)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71fc06fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'facts': {'facts': ['AI adoption increased 40% in 2024.',\n",
       "   'This creates positive opportunities but requires adaptation.'],\n",
       "  'entities': ['AI', '2024'],\n",
       "  'statistics': ['40%'],\n",
       "  'summary': 'AI adoption saw a 40% increase in 2024, leading to positive opportunities while necessitating adaptation.',\n",
       "  'key_points': ['AI adoption is growing.',\n",
       "   'Significant growth occurred in 2024.',\n",
       "   'Adaptation is required due to increased AI adoption.']},\n",
       " 'sentiment': {'sentiment': 'neutral',\n",
       "  'confidence': 0.75,\n",
       "  'tone': [],\n",
       "  'justification': \"The text describes growth and adaptation related to AI adoption. While growth can be seen as positive, the text itself doesn't express explicit positive or negative feelings. It's primarily descriptive and factual. The statement 'Adaptation is required' implies a need for change, which isn't inherently positive or negative without further context.\"},\n",
       " 'enhanced_summary': 'AI adoption is growing, with significant growth occurring in 2024, necessitating adaptation.\\n'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependent_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c15d66",
   "metadata": {},
   "source": [
    "## Tool-Enabled Agents: Adding External Capabilities\n",
    "\n",
    "So far our agents have only worked with the information they receive as input. But what if they need to gather additional information? This is where **tool-enabled agents** come in!\n",
    "\n",
    "### The ToolRegistry Class\n",
    "\n",
    "This class provides our agents with external capabilities:\n",
    "\n",
    "1. **Web Search**: Using Brave Search API to find current information\n",
    "2. **Wikipedia Search**: Accessing Wikipedia's knowledge base\n",
    "3. **Dynamic Tool Discovery**: Agents can discover what tools are available\n",
    "4. **Error Handling**: Graceful handling of API failures\n",
    "\n",
    "**Key Concept**: Tools extend agent capabilities beyond just text processing, allowing them to interact with the external world.\n",
    "\n",
    "### 🛠️ Tool Registry Architecture\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────┐\n",
    "│                   ToolRegistry                          │\n",
    "├─────────────────────────────────────────────────────────┤\n",
    "│                                                         │\n",
    "│  ┌─────────────────┐    ┌──────────────────┐            │\n",
    "│  │   web_search()  │    │wikipedia_search()│            │\n",
    "│  ├─────────────────┤    ├──────────────────┤            │\n",
    "│  │ • Query: str    │    │ • Query: str     │            │\n",
    "│  │ • Max results   │    │ • Sentences      │            │\n",
    "│  │ • API handling  │    │ • Error handling │            │\n",
    "│  └─────────────────┘    └──────────────────┘            │\n",
    "│           │                       │                     │\n",
    "│           ▼                       ▼                     │\n",
    "│  ┌─────────────────┐    ┌─────────────────┐             │\n",
    "│  │ Brave Search    │    │ Wikipedia API   │             │\n",
    "│  │ Results         │    │ Results         │             │\n",
    "│  └─────────────────┘    └─────────────────┘             │\n",
    "└─────────────────────────────────────────────────────────┘\n",
    "                              │\n",
    "                              ▼\n",
    "┌─────────────────────────────────────────────────────────┐\n",
    "│              Agent + Tools Integration                  │\n",
    "├─────────────────────────────────────────────────────────┤\n",
    "│                                                         │\n",
    "│  Agent Internal Knowledge  +  External Tool Access      │\n",
    "│           │                           │                 │\n",
    "│           ▼                           ▼                 │\n",
    "│  ┌─────────────────┐         ┌─────────────────┐        │\n",
    "│  │ LLM Reasoning   │         │ Real-time Data  │        │\n",
    "│  │ • Patterns      │         │ • Current Info  │        │\n",
    "│  │ • Training Data │         │ • Specific Facts│        │\n",
    "│  │ • Analysis      │         │ • External APIs │        │\n",
    "│  └─────────────────┘         └─────────────────┘        │\n",
    "│           │                           │                 │\n",
    "│           └───────────┬───────────────┘                 │\n",
    "│                       ▼                                 │\n",
    "│              Enhanced Agent Output                      │\n",
    "└─────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a53ad75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolRegistry:\n",
    "    \"\"\"Registry of tools that agents can use\"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def get_available_tools(cls) -> str:\n",
    "        \"\"\"Get formatted description of all available tools\"\"\"\n",
    "        tools_description = []\n",
    "        \n",
    "        import inspect\n",
    "        # Use inspect.isfunction since we're using @staticmethod\n",
    "        for name, method in inspect.getmembers(cls, predicate=inspect.isfunction):\n",
    "            if not name.startswith('_') and name != 'get_available_tools':  # Skip private methods and self\n",
    "                # Get the docstring\n",
    "                doc = inspect.getdoc(method)\n",
    "                if doc:\n",
    "                    # Extract the first line as description\n",
    "                    description = doc.split('\\n')[0].strip()\n",
    "                    \n",
    "                    # Get function signature\n",
    "                    sig = inspect.signature(method)\n",
    "                    params = []\n",
    "                    for param_name, param in sig.parameters.items():\n",
    "                        param_type = param.annotation.__name__ if param.annotation != inspect.Parameter.empty else 'any'\n",
    "                        default = f\" = {param.default}\" if param.default != inspect.Parameter.empty else \"\"\n",
    "                        params.append(f\"{param_name}: {param_type}{default}\")\n",
    "                    \n",
    "                    params_str = \", \".join(params)\n",
    "                    tools_description.append(f\"- {name}({params_str}) - {description}\")\n",
    "        \n",
    "        return \"\\n\".join(tools_description)\n",
    "\n",
    "    @staticmethod\n",
    "    def web_search(query: str, max_results: int = 5) -> Dict:\n",
    "        \"\"\"\n",
    "        Performs a web search using Brave Search API and returns a summary of the top results.\n",
    "\n",
    "        Requires BRAVE_SEARCH_API_KEY environment variable to be set.\n",
    "\n",
    "        Args:\n",
    "            query (str): The search query.\n",
    "            max_results (int): The maximum number of search results to return (Brave API limit might be 20 for free tier).\n",
    "\n",
    "        Returns:\n",
    "            Dict: A dictionary containing the query and a list of search results.\n",
    "                  Each result includes 'title', 'url', and 'snippet'.\n",
    "                  Includes an 'error' key if the search fails.\n",
    "        \"\"\"\n",
    "        print(f\"Tool Call: web_search(query='{query}', max_results={max_results})\")\n",
    "        \n",
    "        brave_api_key = os.getenv(\"BRAVE_SEARCH_API_KEY\")\n",
    "        if not brave_api_key:\n",
    "            return {\"error\": \"BRAVE_SEARCH_API_KEY environment variable not set. Please get a key from brave.com/search/api/\"}\n",
    "\n",
    "        headers = {\n",
    "            \"X-Subscription-Token\": brave_api_key,\n",
    "            \"Accept\": \"application/json\"\n",
    "        }\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"count\": min(max_results, 10), # Brave free tier often limits to 20 results per call\n",
    "            \"search_lang\": \"en\"\n",
    "        }\n",
    "\n",
    "        results = []\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                \"https://api.search.brave.com/res/v1/web/search\",\n",
    "                headers=headers,\n",
    "                params=params\n",
    "            )\n",
    "            response.raise_for_status() # Raises HTTPError for bad responses (4xx or 5xx)\n",
    "            data = response.json()\n",
    "\n",
    "            if 'web' in data and 'results' in data['web']:\n",
    "                for r in data['web']['results']:\n",
    "                    results.append({\n",
    "                        \"title\": r.get(\"title\", \"N/A\"),\n",
    "                        \"url\": r.get(\"url\", \"N/A\"),\n",
    "                        \"snippet\": r.get(\"description\", \"N/A\") # Brave API uses 'description' for snippet\n",
    "                    })\n",
    "            else:\n",
    "                return {\"query\": query, \"results\": [], \"error\": \"No 'web' or 'results' key found in Brave API response.\"}\n",
    "\n",
    "        except requests.exceptions.HTTPError as http_err:\n",
    "            return {\"query\": query, \"results\": [], \"error\": f\"HTTP error occurred: {http_err} - {response.text}\"}\n",
    "        except requests.exceptions.ConnectionError as conn_err:\n",
    "            return {\"query\": query, \"results\": [], \"error\": f\"Connection error: {conn_err}\"}\n",
    "        except requests.exceptions.Timeout as timeout_err:\n",
    "            return {\"query\": query, \"results\": [], \"error\": f\"Timeout error: {timeout_err}\"}\n",
    "        except requests.exceptions.RequestException as req_err:\n",
    "            return {\"query\": query, \"results\": [], \"error\": f\"An unexpected request error occurred: {req_err}\"}\n",
    "        except Exception as e:\n",
    "            return {\"query\": query, \"results\": [], \"error\": f\"An unexpected error occurred during Brave search: {e}\"}\n",
    "\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"results\": results\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def wikipedia_search(query: str, sentences: int = 3) -> Dict:\n",
    "        \"\"\"\n",
    "        Searches Wikipedia for a query and returns a summary and URL of the page.\n",
    "\n",
    "        Args:\n",
    "            query (str): The search query for Wikipedia.\n",
    "            sentences (int): The number of sentences to retrieve for the summary.\n",
    "\n",
    "        Returns:\n",
    "            Dict: A dictionary containing the query, title, summary, and URL of the Wikipedia page.\n",
    "                  Returns 'error' if the page is not found.\n",
    "        \"\"\"\n",
    "        print(f\"Tool Call: wikipedia_search(query='{query}', sentences={sentences})\")\n",
    "        # It's good practice to provide a user_agent to Wikipedia API\n",
    "        # Replace 'your_email@example.com' with an actual contact email.\n",
    "        wiki_wiki = wikipediaapi.Wikipedia(language='en', user_agent=\"AgenticFrameworkTutorial/1.0 (sajjad.riaj@gmail.com)\")\n",
    "        \n",
    "        page = wiki_wiki.page(query)\n",
    "\n",
    "        if page.exists():\n",
    "            # Truncate summary gracefully if it's too long\n",
    "            summary_text = page.summary\n",
    "            # A rough heuristic for sentences to words: ~15-20 words per sentence\n",
    "            if len(summary_text.split()) > sentences * 20: \n",
    "                summary_text = ' '.join(summary_text.split()[:sentences * 20]) + \"...\"\n",
    "\n",
    "            return {\n",
    "                \"query\": query,\n",
    "                \"title\": page.title,\n",
    "                \"summary\": summary_text,\n",
    "                \"url\": page.fullurl\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"query\": query,\n",
    "                \"error\": f\"No Wikipedia page found for '{query}'.\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db93c173",
   "metadata": {},
   "source": [
    "## Test the tools\n",
    "\n",
    "Now lets test the tools and their functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45d331d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Testing web_search (Brave API) ---\n",
      "Tool Call: web_search(query='latest AI trends 2025', max_results=3)\n",
      "{'query': 'latest AI trends 2025', 'results': [{'title': '6 AI trends you’ll see more of in 2025', 'url': 'https://news.microsoft.com/source/features/ai/6-ai-trends-youll-see-more-of-in-2025/', 'snippet': '“We’ll start to see these tools ... drugs,” Llorens says.  · In 2025, one trend is certain: <strong>AI will continue to drive innovation and unlock new potential for people and organizations around the globe</strong>....'}, {'title': \"AI Patent Trends Signal Tomorrow's Technologies - Patent - China\", 'url': 'https://www.mondaq.com/china/patent/1643334/ai-patent-trends-signal-tomorrows-technologies', 'snippet': 'Artificial intelligence (<strong>AI</strong>) is the ultimate buzzword at the moment. But from a patent-based perspective, it is more than just the new fad: it is a pointer to technological developments and signals...'}, {'title': 'Latest AI Breakthroughs and News: May, June, July 2025 | News', 'url': 'https://www.crescendo.ai/news/latest-ai-news-and-updates', 'snippet': 'Date: June 20, 2025 Summary: A Gallup report shows that AI usage in the workplace has nearly doubled in the U.S. over two years. <strong>Employee AI use rose from 21% to 40%, with daily users doubling from 4% to 8%</strong>. Weekly AI usage also jumped from 11% to 19%, highlighting rapid adoption. The trend ...'}]}\n",
      "Tool Call: web_search(query='quantum computing breakthroughs', max_results=1)\n",
      "{'query': 'quantum computing breakthroughs', 'results': [{'title': 'Microsoft’s Majorana 1 chip carves new path for quantum computing - Source', 'url': 'https://news.microsoft.com/source/features/innovation/microsofts-majorana-1-chip-carves-new-path-for-quantum-computing/', 'snippet': 'Microsoft today introduced Majorana ... architecture that it expects will realize <strong>quantum</strong> <strong>computers</strong> capable of solving meaningful, industrial-scale problems in years, not decades. It leverages the world’s first topoconductor, a <strong>breakthrough</strong> type of material which can observe and control ...'}]}\n",
      "\n",
      "--- Testing wikipedia_search ---\n",
      "Tool Call: wikipedia_search(query='Artificial General Intelligence', sentences=3)\n",
      "{   'query': 'Artificial General Intelligence',\n",
      "    'title': 'Artificial general intelligence',\n",
      "    'summary': 'Artificial general intelligence (AGI)—sometimes called '\n",
      "               'human‑level intelligence AI—is a type of artificial '\n",
      "               'intelligence that would match or surpass human capabilities '\n",
      "               'across virtually all cognitive tasks. Some researchers argue '\n",
      "               'that state‑of‑the‑art large language models already exhibit '\n",
      "               'early signs of AGI‑level capability, while others maintain '\n",
      "               'that genuine AGI has not yet been achieved. AGI is '\n",
      "               'conceptually distinct from artificial superintelligence (ASI), '\n",
      "               'which...',\n",
      "    'url': 'https://en.wikipedia.org/wiki/Artificial_general_intelligence'}\n",
      "Tool Call: wikipedia_search(query='Generative AI', sentences=1)\n",
      "{   'query': 'Generative AI',\n",
      "    'title': 'Generative artificial intelligence',\n",
      "    'summary': 'Generative artificial intelligence (Generative AI, GenAI, or '\n",
      "               'GAI) is a subfield of artificial intelligence that uses '\n",
      "               'generative models to produce...',\n",
      "    'url': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence'}\n",
      "Tool Call: wikipedia_search(query='NonExistentTopicForSure12345', sentences=3)\n",
      "{   'query': 'NonExistentTopicForSure12345',\n",
      "    'error': \"No Wikipedia page found for 'NonExistentTopicForSure12345'.\"}\n"
     ]
    }
   ],
   "source": [
    "# Make sure to set your BRAVE_SEARCH_API_KEY environment variable before running!\n",
    "\n",
    "print(\"--- Testing web_search (Brave API) ---\")\n",
    "web_results = ToolRegistry.web_search(\"latest AI trends 2025\", max_results=3)\n",
    "print(web_results)\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "web_results_short = ToolRegistry.web_search(\"quantum computing breakthroughs\", max_results=1)\n",
    "print(web_results_short)\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "print(\"\\n--- Testing wikipedia_search ---\")\n",
    "wiki_results = ToolRegistry.wikipedia_search(\"Artificial General Intelligence\")\n",
    "pp(wiki_results, indent=4)\n",
    "\n",
    "wiki_results_short = ToolRegistry.wikipedia_search(\"Generative AI\", sentences=1)\n",
    "pp(wiki_results_short, indent=4)\n",
    "\n",
    "wiki_not_found = ToolRegistry.wikipedia_search(\"NonExistentTopicForSure12345\")\n",
    "pp(wiki_not_found, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda5cac2",
   "metadata": {},
   "source": [
    "## 12. Advanced Agent Architecture: Tool-Enabled Agents\n",
    "\n",
    "Now let's build our most sophisticated agents yet! These agents can:\n",
    "\n",
    "1. **Decide** which tools to use based on the query\n",
    "2. **Execute** the tools with appropriate parameters\n",
    "3. **Synthesize** the results into a comprehensive response\n",
    "\n",
    "### The Three-Step Process:\n",
    "\n",
    "1. **Tool Decision**: The agent analyzes the query and decides which tools it needs\n",
    "2. **Tool Execution**: The agent calls the selected tools with generated parameters\n",
    "3. **Result Synthesis**: The agent combines tool outputs with its own analysis\n",
    "\n",
    "This is a powerful pattern that mimics how humans solve complex problems by gathering information from multiple sources.\n",
    "\n",
    "### 🧠 Advanced Tool-Enabled Agent Architecture\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│              FactExtractorAgentToolsEnabled                     │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                 │\n",
    "│  Step 1: TOOL DECISION                                          │\n",
    "│  ┌─────────────────────────────────────────────────────────┐    │\n",
    "│  │  Query Analysis                                         │    │\n",
    "│  │  • What information is needed?                          │    │\n",
    "│  │  • Which tools can provide it?                          │    │\n",
    "│  │  • What parameters to use?                              │    │\n",
    "│  │                                                         │    │\n",
    "│  │  Input: \"Tell me about iPhone 15\"                       │    │\n",
    "│  │  Decision: Use web_search(\"iPhone 15 specs\")            │    │\n",
    "│  └─────────────────────────────────────────────────────────┘    │\n",
    "│                              │                                  │\n",
    "│                              ▼                                  │\n",
    "│  Step 2: TOOL EXECUTION                                         │\n",
    "│  ┌──────────────────────────────────────────────────────────┐   │\n",
    "│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐       │   │\n",
    "│  │  │ web_search  │  │ wikipedia   │  │  Other      │       │   │\n",
    "│  │  │ (if needed) │  │ (if needed) │  │  Tools      │       │   │\n",
    "│  │  └─────────────┘  └─────────────┘  └─────────────┘       │   │\n",
    "│  │         │                │                │              │   │\n",
    "│  │         ▼                ▼                ▼              │   │\n",
    "│  │  ┌─────────────────────────────────────────────────────┐ │   │\n",
    "│  │  │           Tool Results Collection                   │ │   │\n",
    "│  │  │  • Web search results                               │ │   │\n",
    "│  │  │  • Wikipedia summaries                              │ │   │\n",
    "│  │  │  • Error handling                                   │ │   │\n",
    "│  │  └─────────────────────────────────────────────────────┘ │   │\n",
    "│  └──────────────────────────────────────────────────────────┘   │\n",
    "│                              │                                  │\n",
    "│                              ▼                                  │\n",
    "│  Step 3: RESULT SYNTHESIS                                       │\n",
    "│  ┌─────────────────────────────────────────────────────────┐    │\n",
    "│  │  Original Query + Tool Results + Agent Analysis         │    │\n",
    "│  │                        │                                │    │\n",
    "│  │                        ▼                                │    │\n",
    "│  │  ┌─────────────────────────────────────────────────┐    │    │\n",
    "│  │  │          LLM Synthesis                          │    │    │\n",
    "│  │  │  • Combine information                          │    │    │\n",
    "│  │  │  • Extract facts                                │    │    │\n",
    "│  │  │  • Cite sources                                 │    │    │\n",
    "│  │  │  • Structure output                             │    │    │\n",
    "│  │  └─────────────────────────────────────────────────┘    │    │\n",
    "│  │                        │                                │    │\n",
    "│  │                        ▼                                │    │\n",
    "│  │  ┌─────────────────────────────────────────────────┐    │    │\n",
    "│  │  │        Comprehensive Response                   │    │    │\n",
    "│  │  │  {                                              │    │    │\n",
    "│  │  │    \"facts\": [...],                              │    │    │\n",
    "│  │  │    \"sources_used\": [...],                       │    │    │\n",
    "│  │  │    \"confidence\": 0.95,                          │    │    │\n",
    "│  │  │    \"summary\": \"...\",                            │    │    │\n",
    "│  │  │    \"tool_decision\": {...},                      │    │    │\n",
    "│  │  │    \"tool_results\": {...}                        │    │    │\n",
    "│  │  │  }                                              │    │    │\n",
    "│  │  └─────────────────────────────────────────────────┘    │    │\n",
    "│  └─────────────────────────────────────────────────────────┘    │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "\n",
    "DECIDE → EXECUTE → SYNTHESIZE\n",
    "Human-like Problem Solving\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d079306",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactExtractorAgentToolsEnabled(BaseAgent):\n",
    "    \"\"\"Fact agent that can decide to use tools\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            \"FactAgent\", \n",
    "            \"You are a fact extraction agent. You can use web search and Wikipedia tools when needed.\"\n",
    "        )\n",
    "        self.tools = ToolRegistry()\n",
    "    \n",
    "    def handle_query(self, query: str) -> Dict:\n",
    "        \"\"\"Main method: decide tools → execute tools → synthesize\"\"\"\n",
    "        print(f\"\\n🤖 [{self.name}] Received query: {query}\")\n",
    "        \n",
    "        # Step 1: Decide which tools to use and generate params\n",
    "        tool_decision = self._decide_tools(query)\n",
    "        print(f\"🔧 [{self.name}] Tool decision: {tool_decision}\")\n",
    "        \n",
    "        # Step 2: Execute the tools\n",
    "        tool_results = self._execute_tools(tool_decision)\n",
    "        print(f\"📊 [{self.name}] Tool execution complete\")\n",
    "        \n",
    "        # Step 3: Synthesize final result\n",
    "        final_result = self._synthesize_result(query, tool_decision, tool_results)\n",
    "        print(f\"✅ [{self.name}] Result synthesized\")\n",
    "        \n",
    "        return final_result\n",
    "    \n",
    "    def _decide_tools(self, query: str) -> Dict:\n",
    "        \"\"\"Step 1: Decide which tools to use and generate parameters\"\"\"\n",
    "        print(f\"🧠 [{self.name}] Deciding which tools to use...\")\n",
    "        \n",
    "        # Get available tools from ToolRegistry\n",
    "        available_tools = ToolRegistry.get_available_tools()\n",
    "        \n",
    "        decision_prompt = f\"\"\"\n",
    "        Query: {query}\n",
    "        \n",
    "        Available tools:\n",
    "        {available_tools}\n",
    "        \n",
    "        Decide which tools to use for this query and generate the parameters.\n",
    "        \n",
    "        Respond with JSON:\n",
    "        {{\n",
    "            \"tools_to_use\": [\n",
    "                {{\n",
    "                    \"tool\": \"tool_name\",\n",
    "                    \"params\": {{\"param1\": \"value1\", \"param2\": \"value2\"}}\n",
    "                }}\n",
    "            ],\n",
    "            \"reasoning\": \"why these tools and params\"\n",
    "        }}\n",
    "        \n",
    "        Use empty list [] if no tools needed.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.process(decision_prompt)\n",
    "        return extract_and_parse_json(response)\n",
    "    \n",
    "    def _execute_tools(self, tool_decision: Dict) -> Dict:\n",
    "        \"\"\"Step 2: Execute the decided tools with their parameters\"\"\"\n",
    "        print(f\"⚡ [{self.name}] Executing tools...\")\n",
    "        \n",
    "        tool_results = {}\n",
    "        tools_to_use = tool_decision.get(\"tools_to_use\", [])\n",
    "        \n",
    "        for i, tool_call in enumerate(tools_to_use):\n",
    "            tool_name = tool_call.get(\"tool\")\n",
    "            params = tool_call.get(\"params\", {})\n",
    "            \n",
    "            print(f\"🔍 [{self.name}] Executing {tool_name} with params: {params}\")\n",
    "            \n",
    "            # Use getattr to call tools dynamically\n",
    "            if hasattr(self.tools, tool_name):\n",
    "                tool_method = getattr(self.tools, tool_name)\n",
    "                try:\n",
    "                    result = tool_method(**params)\n",
    "                except TypeError as e:\n",
    "                    result = {\"error\": f\"Invalid parameters for {tool_name}: {e}\"}\n",
    "            else:\n",
    "                result = {\"error\": f\"Tool {tool_name} not found in ToolRegistry\"}\n",
    "            \n",
    "            tool_results[f\"{tool_name}_{i}\"] = result\n",
    "            print(f\"📋 [{self.name}] {tool_name} completed\")\n",
    "        \n",
    "        return tool_results\n",
    "    \n",
    "    def _synthesize_result(self, original_query: str, tool_decision: Dict, tool_results: Dict) -> Dict:\n",
    "        \"\"\"Step 3: Synthesize final result from tools and original query\"\"\"\n",
    "        print(f\"🧬 [{self.name}] Synthesizing final result...\")\n",
    "        \n",
    "        synthesis_prompt = f\"\"\"\n",
    "        Original query: {original_query}\n",
    "        \n",
    "        Tool decision made: {json.dumps(tool_decision, indent=2)}\n",
    "        \n",
    "        Tool results: {json.dumps(tool_results, indent=2)}\n",
    "        \n",
    "        Now extract facts and synthesize a comprehensive response.\n",
    "        \n",
    "        Return JSON:\n",
    "        {{\n",
    "            \"facts\": [\"fact1\", \"fact2\", \"fact3\"],\n",
    "            \"entities\": [\"entity1\", \"entity2\"],\n",
    "            \"summary\": \"summary of all findings\",\n",
    "            \"sources_used\": [\"source1\", \"source2\"],\n",
    "            \"confidence\": 0.0-1.0\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.process(synthesis_prompt)\n",
    "        synthesis = extract_and_parse_json(response)\n",
    "        \n",
    "        # Return complete result\n",
    "        return {\n",
    "            \"agent\": self.name,\n",
    "            \"original_query\": original_query,\n",
    "            \"tool_decision\": tool_decision,\n",
    "            \"tool_results\": tool_results,\n",
    "            \"final_synthesis\": synthesis\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35337ed",
   "metadata": {},
   "source": [
    "### Tool-Enabled Sentiment Analyzer\n",
    "\n",
    "Here's our sentiment analyzer with tool capabilities. It can search for additional context about topics to provide more informed sentiment analysis.\n",
    "\n",
    "**Use Cases:**\n",
    "- Analyzing sentiment about products/services by looking up reviews\n",
    "- Understanding context around events or topics\n",
    "- Providing more nuanced sentiment analysis with background information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6186bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalyzerAgentToolsEnabled(BaseAgent):\n",
    "    \"\"\"Sentiment agent that can decide to use tools\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            \"SentimentAgent\",\n",
    "            \"You are a sentiment analysis agent. You can use web search and Wikipedia tools for context.\"\n",
    "        )\n",
    "        self.tools = ToolRegistry()\n",
    "    \n",
    "    def handle_query(self, query: str) -> Dict:\n",
    "        \"\"\"Main method: decide tools → execute tools → synthesize\"\"\"\n",
    "        print(f\"\\n😊 [{self.name}] Received query: {query}\")\n",
    "        \n",
    "        # Step 1: Decide which tools to use and generate params\n",
    "        tool_decision = self._decide_tools(query)\n",
    "        print(f\"🔧 [{self.name}] Tool decision: {tool_decision}\")\n",
    "        \n",
    "        # Step 2: Execute the tools\n",
    "        tool_results = self._execute_tools(tool_decision)\n",
    "        print(f\"📊 [{self.name}] Tool execution complete\")\n",
    "        \n",
    "        # Step 3: Synthesize final result\n",
    "        final_result = self._synthesize_result(query, tool_decision, tool_results)\n",
    "        print(f\"✅ [{self.name}] Result synthesized\")\n",
    "        \n",
    "        return final_result\n",
    "    \n",
    "    def _decide_tools(self, query: str) -> Dict:\n",
    "        \"\"\"Step 1: Decide which tools to use and generate parameters\"\"\"\n",
    "        print(f\"🧠 [{self.name}] Deciding which tools to use...\")\n",
    "        \n",
    "        # Get available tools from ToolRegistry\n",
    "        available_tools = ToolRegistry.get_available_tools()\n",
    "        \n",
    "        decision_prompt = f\"\"\"\n",
    "        Query: {query}\n",
    "        \n",
    "        Available tools:\n",
    "        {available_tools}\n",
    "        \n",
    "        Decide which tools to use for better sentiment analysis and generate the parameters.\n",
    "        \n",
    "        Respond with JSON:\n",
    "        {{\n",
    "            \"tools_to_use\": [\n",
    "                {{\n",
    "                    \"tool\": \"tool_name\",\n",
    "                    \"params\": {{\"param1\": \"value1\", \"param2\": \"value2\"}}\n",
    "                }}\n",
    "            ],\n",
    "            \"reasoning\": \"why these tools help with sentiment analysis\"\n",
    "        }}\n",
    "        \n",
    "        Use empty list [] if no tools needed.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.process(decision_prompt)\n",
    "        return extract_and_parse_json(response)\n",
    "    \n",
    "    def _execute_tools(self, tool_decision: Dict) -> Dict:\n",
    "        \"\"\"Step 2: Execute the decided tools with their parameters\"\"\"\n",
    "        print(f\"⚡ [{self.name}] Executing tools...\")\n",
    "        \n",
    "        tool_results = {}\n",
    "        tools_to_use = tool_decision.get(\"tools_to_use\", [])\n",
    "        \n",
    "        for i, tool_call in enumerate(tools_to_use):\n",
    "            tool_name = tool_call.get(\"tool\")\n",
    "            params = tool_call.get(\"params\", {})\n",
    "            \n",
    "            print(f\"🔍 [{self.name}] Executing {tool_name} with params: {params}\")\n",
    "            \n",
    "            # Use getattr to call tools dynamically\n",
    "            if hasattr(self.tools, tool_name):\n",
    "                tool_method = getattr(self.tools, tool_name)\n",
    "                try:\n",
    "                    result = tool_method(**params)\n",
    "                except TypeError as e:\n",
    "                    result = {\"error\": f\"Invalid parameters for {tool_name}: {e}\"}\n",
    "            else:\n",
    "                result = {\"error\": f\"Tool {tool_name} not found in ToolRegistry\"}\n",
    "            \n",
    "            tool_results[f\"{tool_name}_{i}\"] = result\n",
    "            print(f\"📋 [{self.name}] {tool_name} completed\")\n",
    "        \n",
    "        return tool_results\n",
    "    \n",
    "    def _synthesize_result(self, original_query: str, tool_decision: Dict, tool_results: Dict) -> Dict:\n",
    "        \"\"\"Step 3: Synthesize final result from tools and original query\"\"\"\n",
    "        print(f\"🧬 [{self.name}] Synthesizing final result...\")\n",
    "        \n",
    "        synthesis_prompt = f\"\"\"\n",
    "        Original query: {original_query}\n",
    "        \n",
    "        Tool decision made: {json.dumps(tool_decision, indent=2)}\n",
    "        \n",
    "        Tool results: {json.dumps(tool_results, indent=2)}\n",
    "        \n",
    "        Now analyze sentiment using the original query and any context from tools.\n",
    "        \n",
    "        Return JSON:\n",
    "        {{\n",
    "            \"sentiment\": \"positive/negative/neutral\",\n",
    "            \"confidence\": 0.0-1.0,\n",
    "            \"tone\": [\"emotion1\", \"emotion2\"],\n",
    "            \"justification\": \"why this sentiment\",\n",
    "            \"context_influence\": \"how tool results influenced analysis\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.process(synthesis_prompt)\n",
    "        synthesis = extract_and_parse_json(response)\n",
    "        \n",
    "        # Return complete result\n",
    "        return {\n",
    "            \"agent\": self.name,\n",
    "            \"original_query\": original_query,\n",
    "            \"tool_decision\": tool_decision,\n",
    "            \"tool_results\": tool_results,\n",
    "            \"final_synthesis\": synthesis\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71fb0ae",
   "metadata": {},
   "source": [
    "## 13. Multi-Agent Orchestration: The Orchestrator\n",
    "\n",
    "Finally, let's build an **Orchestrator** - a meta-agent that coordinates other agents! This demonstrates the pinnacle of agent architecture.\n",
    "\n",
    "### The Orchestrator's Role:\n",
    "\n",
    "1. **Request Analysis**: Understands what the user is asking for\n",
    "2. **Agent Selection**: Decides which specialized agents to use\n",
    "3. **Task Delegation**: Assigns work to the appropriate agents\n",
    "4. **Result Integration**: Combines outputs from multiple agents\n",
    "\n",
    "### Why This Matters:\n",
    "\n",
    "- **Scalability**: Easy to add new specialized agents\n",
    "- **Flexibility**: Can handle complex requests requiring multiple capabilities\n",
    "- **Maintainability**: Each agent focuses on what it does best\n",
    "- **User Experience**: Single interface that handles complex multi-step tasks\n",
    "\n",
    "This pattern is used in many real-world AI systems!\n",
    "\n",
    "### 🎭 Multi-Agent Orchestration Architecture\n",
    "\n",
    "```\n",
    "                    ┌─────────────────────────────────┐\n",
    "                    │          USER REQUEST           │\n",
    "                    │   \"Facts about iPhone 15 and   │\n",
    "                    │    how people feel about it\"    │\n",
    "                    └─────────────────┬───────────────┘\n",
    "                                      │\n",
    "                                      ▼\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                      ORCHESTRATOR                               │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                 │\n",
    "│  Step 1: REQUEST ANALYSIS                                       │\n",
    "│  ┌─────────────────────────────────────────────────────────┐    │\n",
    "│  │  • Parse user intent                                    │    │\n",
    "│  │  • Identify required capabilities                       │    │\n",
    "│  │  • Determine agent delegation strategy                  │    │\n",
    "│  └─────────────────────────────────────────────────────────┘    │\n",
    "│                              │                                  │\n",
    "│                              ▼                                  │\n",
    "│  Step 2: AGENT DELEGATION                                       │\n",
    "│  ┌─────────────────────────────────────────────────────────┐    │\n",
    "│  │         Decision: Use both agents                       │    │\n",
    "│  │  ┌─────────────────┐    ┌─────────────────┐             │    │\n",
    "│  │  │ use_fact_agent  │    │use_sentiment_   │             │    │\n",
    "│  │  │    = true       │    │   agent = true  │             │    │\n",
    "│  │  └─────────────────┘    └─────────────────┘             │    │\n",
    "│  └─────────────────────────────────────────────────────────┘    │\n",
    "│                              │                                  │\n",
    "│                              ▼                                  │\n",
    "│  Step 3: PARALLEL EXECUTION                                     │\n",
    "│  ┌─────────────────────────────────────────────────────────┐    │\n",
    "│  │                                                         │    │\n",
    "│  │  ┌─────────────────────┐  ┌──────────────────────┐      │    │\n",
    "│  │  │ FactExtractorAgent  │  │SentimentAnalyzerAgent│      │    │\n",
    "│  │  │   (Tools Enabled)   │  │   (Tools Enabled)    │      │    │\n",
    "│  │  └─────────────────────┘  └──────────────────────┘      │    │\n",
    "│  │            │                          │                 │    │\n",
    "│  │            ▼                          ▼                 │    │\n",
    "│  │  ┌─────────────────────┐  ┌─────────────────────┐       │    │\n",
    "│  │  │   Tool Decision     │  │   Tool Decision     │       │    │\n",
    "│  │  │   Tool Execution    │  │   Tool Execution    │       │    │\n",
    "│  │  │   Result Synthesis  │  │   Result Synthesis  │       │    │\n",
    "│  │  └─────────────────────┘  └─────────────────────┘       │    │\n",
    "│  │            │                          │                 │    │\n",
    "│  │            ▼                          ▼                 │    │\n",
    "│  │  ┌─────────────────────┐  ┌─────────────────────┐       │    │\n",
    "│  │  │   Facts + Sources   │  │ Sentiment + Context │       │    │\n",
    "│  │  └─────────────────────┘  └─────────────────────┘       │    │\n",
    "│  └─────────────────────────────────────────────────────────┘    │\n",
    "│                              │                                  │\n",
    "│                              ▼                                  │\n",
    "│  Step 4: RESULT INTEGRATION                                     │\n",
    "│  ┌─────────────────────────────────────────────────────────┐    │\n",
    "│  │           Combined Multi-Agent Response                 │    │\n",
    "│  │  {                                                      │    │\n",
    "│  │    \"request\": \"original query\",                         │    │\n",
    "│  │    \"delegation_decision\": {...},                        │    │\n",
    "│  │    \"agent_results\": {                                   │    │\n",
    "│  │      \"facts\": {agent output with tools},                │    │\n",
    "│  │      \"sentiment\": {agent output with tools}             │    │\n",
    "│  │    }                                                    │    │\n",
    "│  │  }                                                      │    │\n",
    "│  └─────────────────────────────────────────────────────────┘    │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "                              │\n",
    "                              ▼\n",
    "                    ┌─────────────────────────────────┐\n",
    "                    │      COMPREHENSIVE RESPONSE     │\n",
    "                    │   Facts + Sentiment + Sources   │\n",
    "                    │     from Multiple Agents        │\n",
    "                    └─────────────────────────────────┘\n",
    "\n",
    "ONE REQUEST → MULTIPLE SPECIALIZED AGENTS → INTEGRATED RESPONSE\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c819118",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Orchestrator(BaseAgent):\n",
    "    \"\"\"Simple orchestrator that delegates to agents\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            \"Orchestrator\",\n",
    "            \"You decide which agents to use for different queries.\"\n",
    "        )\n",
    "        \n",
    "        self.fact_agent = FactExtractorAgentToolsEnabled()\n",
    "        self.sentiment_agent = SentimentAnalyzerAgentToolsEnabled()\n",
    "        \n",
    "        print(f\"🎯 [{self.name}] Ready with fact and sentiment agents\")\n",
    "    \n",
    "    def handle_request(self, user_request: str) -> Dict:\n",
    "        \"\"\"Delegate to appropriate agents\"\"\"\n",
    "        print(f\"\\n🎬 [{self.name}] Processing: {user_request}\")\n",
    "        \n",
    "        # Decide which agents to use\n",
    "        delegation = self._decide_delegation(user_request)\n",
    "        print(f\"📋 [{self.name}] Delegation: {delegation}\")\n",
    "        \n",
    "        # Execute delegation\n",
    "        results = {}\n",
    "        \n",
    "        if delegation.get(\"use_fact_agent\"):\n",
    "            print(f\"\\n🎯 [{self.name}] Delegating to fact agent...\")\n",
    "            results[\"facts\"] = self.fact_agent.handle_query(user_request)\n",
    "        \n",
    "        if delegation.get(\"use_sentiment_agent\"):\n",
    "            print(f\"\\n🎯 [{self.name}] Delegating to sentiment agent...\")\n",
    "            results[\"sentiment\"] = self.sentiment_agent.handle_query(user_request)\n",
    "        \n",
    "        return {\n",
    "            \"request\": user_request,\n",
    "            \"delegation_decision\": delegation,\n",
    "            \"agent_results\": results\n",
    "        }\n",
    "    \n",
    "    def _decide_delegation(self, request: str) -> Dict:\n",
    "        \"\"\"Decide which agents to use\"\"\"\n",
    "        delegation_prompt = f\"\"\"\n",
    "        Request: {request}\n",
    "        \n",
    "        Available agents:\n",
    "        - fact_agent: Extracts facts, entities, statistics\n",
    "        - sentiment_agent: Analyzes sentiment, emotions, tone\n",
    "        \n",
    "        Which agents should handle this request?\n",
    "        \n",
    "        JSON response:\n",
    "        {{\n",
    "            \"use_fact_agent\": true/false,\n",
    "            \"use_sentiment_agent\": true/false,\n",
    "            \"reasoning\": \"why this delegation\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.process(delegation_prompt)\n",
    "        return extract_and_parse_json(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91c783f",
   "metadata": {},
   "source": [
    "## Testing Our Complete System\n",
    "\n",
    "Let's test our complete multi-agent system! First, let's see what tools are available to our agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e438d29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- web_search(query: str, max_results: int = 5) - Performs a web search using Brave Search API and returns a summary of the top results.\n",
      "- wikipedia_search(query: str, sentences: int = 3) - Searches Wikipedia for a query and returns a summary and URL of the page.\n"
     ]
    }
   ],
   "source": [
    "print(ToolRegistry.get_available_tools())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9767bde",
   "metadata": {},
   "source": [
    "### Initialize the Orchestrator\n",
    "\n",
    "Now let's create our orchestrator that will coordinate all our specialized agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f12ea8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 [Orchestrator] Ready with fact and sentiment agents\n"
     ]
    }
   ],
   "source": [
    "orchestrator = Orchestrator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b558f5",
   "metadata": {},
   "source": [
    "### Complex Test Queries\n",
    "\n",
    "Let's test our system with complex queries that require multiple types of analysis. These queries will demonstrate how the orchestrator intelligently delegates work to different agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d88d241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"What are the facts about the iPhone 15 and how do people feel about it?\",\n",
    "    \"Analyze this review: 'Tesla Model Y is amazing! Great range and autopilot features. Worth every penny!'\",\n",
    "    \"Tell me about recent developments in AI safety\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d058775f",
   "metadata": {},
   "source": [
    "### Running the Complete System Test\n",
    "\n",
    "Now let's run our comprehensive test! Watch how the orchestrator:\n",
    "\n",
    "1. **Analyzes each query** to understand what's needed\n",
    "2. **Delegates to appropriate agents** (fact extraction, sentiment analysis, or both)\n",
    "3. **Coordinates tool usage** when agents need external information\n",
    "4. **Integrates results** into a cohesive response\n",
    "\n",
    "This demonstrates a fully functional multi-agent system in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5605f6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 TEST CASE 1\n",
      "==================================================\n",
      "\n",
      "🎬 [Orchestrator] Processing: What are the facts about the iPhone 15 and how do people feel about it?\n",
      "📋 [Orchestrator] Delegation: {'use_fact_agent': True, 'use_sentiment_agent': True, 'reasoning': 'The query explicitly asks for facts about the iPhone 15, which is the domain of the fact_agent. It also asks how people feel about it, which requires sentiment analysis and is the domain of the sentiment_agent.'}\n",
      "\n",
      "🎯 [Orchestrator] Delegating to fact agent...\n",
      "\n",
      "🤖 [FactAgent] Received query: What are the facts about the iPhone 15 and how do people feel about it?\n",
      "🧠 [FactAgent] Deciding which tools to use...\n",
      "🔧 [FactAgent] Tool decision: {'tools_to_use': [{'tool': 'web_search', 'params': {'query': 'iPhone 15 facts and reviews', 'max_results': 5}}], 'reasoning': 'I will use web search to find information about the facts of the iPhone 15, as well as user opinions and reviews.'}\n",
      "⚡ [FactAgent] Executing tools...\n",
      "🔍 [FactAgent] Executing web_search with params: {'query': 'iPhone 15 facts and reviews', 'max_results': 5}\n",
      "Tool Call: web_search(query='iPhone 15 facts and reviews', max_results=5)\n",
      "📋 [FactAgent] web_search completed\n",
      "📊 [FactAgent] Tool execution complete\n",
      "🧬 [FactAgent] Synthesizing final result...\n",
      "✅ [FactAgent] Result synthesized\n",
      "\n",
      "🎯 [Orchestrator] Delegating to sentiment agent...\n",
      "\n",
      "😊 [SentimentAgent] Received query: What are the facts about the iPhone 15 and how do people feel about it?\n",
      "🧠 [SentimentAgent] Deciding which tools to use...\n",
      "🔧 [SentimentAgent] Tool decision: {'tools_to_use': [{'tool': 'web_search', 'params': {'query': 'iPhone 15 review sentiment', 'max_results': 5}}, {'tool': 'web_search', 'params': {'query': 'iPhone 15 pros and cons', 'max_results': 5}}, {'tool': 'wikipedia_search', 'params': {'query': 'iPhone 15', 'sentences': 3}}], 'reasoning': \"Web search is essential to gather recent reviews and opinions on the iPhone 15, as it aggregates sentiment from various sources like tech blogs, user forums, and news articles. Searching for 'iPhone 15 review sentiment' and 'iPhone 15 pros and cons' directly targets opinions and feedback. Wikipedia provides factual background information about the device, which helps in understanding the context of the sentiments expressed.\"}\n",
      "⚡ [SentimentAgent] Executing tools...\n",
      "🔍 [SentimentAgent] Executing web_search with params: {'query': 'iPhone 15 review sentiment', 'max_results': 5}\n",
      "Tool Call: web_search(query='iPhone 15 review sentiment', max_results=5)\n",
      "📋 [SentimentAgent] web_search completed\n",
      "🔍 [SentimentAgent] Executing web_search with params: {'query': 'iPhone 15 pros and cons', 'max_results': 5}\n",
      "Tool Call: web_search(query='iPhone 15 pros and cons', max_results=5)\n",
      "📋 [SentimentAgent] web_search completed\n",
      "🔍 [SentimentAgent] Executing wikipedia_search with params: {'query': 'iPhone 15', 'sentences': 3}\n",
      "Tool Call: wikipedia_search(query='iPhone 15', sentences=3)\n",
      "📋 [SentimentAgent] wikipedia_search completed\n",
      "📊 [SentimentAgent] Tool execution complete\n",
      "🧬 [SentimentAgent] Synthesizing final result...\n",
      "✅ [SentimentAgent] Result synthesized\n",
      "\n",
      "📊 FINAL RESULTS:\n",
      "\n",
      "FACTS:\n",
      "  Summary: The iPhone 15 features a new design, USB-C port, and advanced features. It receives positive reviews, with the Pro Max model earning top scores. Some reviews note the USB-C 2.0 may be outdated but overall, it's seen as a significant upgrade to the base iPhone.\n",
      "  Confidence: 0.9\n",
      "\n",
      "SENTIMENT:\n",
      "  Summary: N/A\n",
      "  Confidence: 0.7\n",
      "\n",
      "==================================================\n",
      "\n",
      "🧪 TEST CASE 2\n",
      "==================================================\n",
      "\n",
      "🎬 [Orchestrator] Processing: Analyze this review: 'Tesla Model Y is amazing! Great range and autopilot features. Worth every penny!'\n",
      "📋 [Orchestrator] Delegation: {'use_fact_agent': True, 'use_sentiment_agent': True, 'reasoning': \"The review contains factual elements like 'Tesla Model Y', 'range', and 'autopilot', which the fact_agent can extract. Also, the review expresses sentiment ('amazing!', 'Worth every penny!'), making the sentiment_agent relevant for analyzing the emotional tone.\"}\n",
      "\n",
      "🎯 [Orchestrator] Delegating to fact agent...\n",
      "\n",
      "🤖 [FactAgent] Received query: Analyze this review: 'Tesla Model Y is amazing! Great range and autopilot features. Worth every penny!'\n",
      "🧠 [FactAgent] Deciding which tools to use...\n",
      "🔧 [FactAgent] Tool decision: {'tools_to_use': [], 'reasoning': 'The query asks to analyze the sentiment expressed in a short review. No external information is needed to understand the review or identify the entities mentioned.'}\n",
      "⚡ [FactAgent] Executing tools...\n",
      "📊 [FactAgent] Tool execution complete\n",
      "🧬 [FactAgent] Synthesizing final result...\n",
      "✅ [FactAgent] Result synthesized\n",
      "\n",
      "🎯 [Orchestrator] Delegating to sentiment agent...\n",
      "\n",
      "😊 [SentimentAgent] Received query: Analyze this review: 'Tesla Model Y is amazing! Great range and autopilot features. Worth every penny!'\n",
      "🧠 [SentimentAgent] Deciding which tools to use...\n",
      "🔧 [SentimentAgent] Tool decision: {'tools_to_use': [], 'reasoning': \"The review is short, direct, and expresses clear positive sentiment. The words 'amazing,' 'great,' and 'worth every penny' strongly indicate a positive opinion. No further context or clarification is needed to understand the sentiment. Therefore, no external tools are required.\"}\n",
      "⚡ [SentimentAgent] Executing tools...\n",
      "📊 [SentimentAgent] Tool execution complete\n",
      "🧬 [SentimentAgent] Synthesizing final result...\n",
      "✅ [SentimentAgent] Result synthesized\n",
      "\n",
      "📊 FINAL RESULTS:\n",
      "\n",
      "FACTS:\n",
      "  Summary: The review is highly positive, highlighting the Tesla Model Y's impressive range and autopilot features, and concluding that it is a worthwhile purchase.\n",
      "  Confidence: 1.0\n",
      "\n",
      "SENTIMENT:\n",
      "  Summary: N/A\n",
      "  Confidence: 0.99\n",
      "\n",
      "==================================================\n",
      "\n",
      "🧪 TEST CASE 3\n",
      "==================================================\n",
      "\n",
      "🎬 [Orchestrator] Processing: Tell me about recent developments in AI safety\n",
      "📋 [Orchestrator] Delegation: {'use_fact_agent': True, 'use_sentiment_agent': False, 'reasoning': 'The request asks about recent developments in AI safety, which requires extracting factual information about new research, events, or initiatives. Sentiment analysis is not relevant to this request.'}\n",
      "\n",
      "🎯 [Orchestrator] Delegating to fact agent...\n",
      "\n",
      "🤖 [FactAgent] Received query: Tell me about recent developments in AI safety\n",
      "🧠 [FactAgent] Deciding which tools to use...\n",
      "🔧 [FactAgent] Tool decision: {'tools_to_use': [{'tool': 'web_search', 'params': {'query': 'recent developments AI safety', 'max_results': 5}}], 'reasoning': 'To provide information about recent developments in AI safety, a web search is the most appropriate tool. This will help gather the most up-to-date information from various sources, including news articles, research papers, and blog posts. I set the max results to 5 to get a good overview without being overwhelmed.'}\n",
      "⚡ [FactAgent] Executing tools...\n",
      "🔍 [FactAgent] Executing web_search with params: {'query': 'recent developments AI safety', 'max_results': 5}\n",
      "Tool Call: web_search(query='recent developments AI safety', max_results=5)\n",
      "📋 [FactAgent] web_search completed\n",
      "📊 [FactAgent] Tool execution complete\n",
      "🧬 [FactAgent] Synthesizing final result...\n",
      "✅ [FactAgent] Result synthesized\n",
      "\n",
      "📊 FINAL RESULTS:\n",
      "\n",
      "FACTS:\n",
      "  Summary: Recent developments in AI safety involve initiatives to mitigate risks associated with AI development and deployment. These include the establishment of the International Network of AI Safety Institutes, research focused on societal-scale risks by organizations like the Center for AI Safety (CAIS), and the development of safety tools for large language models, such as those released by Meta for Llama 4. Concerns remain regarding the potential for AI competition to lead to unsafe practices and the impact of AI on employment.\n",
      "  Confidence: 0.9\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for i, query in enumerate(test_queries, 1):\n",
    "        print(f\"\\n🧪 TEST CASE {i}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        result = orchestrator.handle_request(query)\n",
    "        \n",
    "        print(f\"\\n📊 FINAL RESULTS:\")\n",
    "        for agent_type, agent_result in result[\"agent_results\"].items():\n",
    "            print(f\"\\n{agent_type.upper()}:\")\n",
    "            if \"final_synthesis\" in agent_result:\n",
    "                synthesis = agent_result[\"final_synthesis\"]\n",
    "                print(f\"  Summary: {synthesis.get('summary', 'N/A')}\")\n",
    "                print(f\"  Confidence: {synthesis.get('confidence', 'N/A')}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645ee424",
   "metadata": {},
   "source": [
    "## Conclusion: Your Journey into LLM Agents\n",
    "\n",
    "Congratulations! You've built a complete multi-agent system from scratch. Let's recap what we've learned:\n",
    "\n",
    "### Key Concepts Covered:\n",
    "\n",
    "1. **Basic Agent Architecture**: LLM + Instructions = Agent\n",
    "2. **Specialized Agents**: Different prompts create different capabilities\n",
    "3. **Structured Output**: JSON responses for programmatic processing\n",
    "4. **Agent Coordination**: Independent vs. Sequential processing patterns\n",
    "5. **Tool Integration**: Extending agents with external capabilities\n",
    "6. **Multi-Agent Orchestration**: Coordinating multiple specialized agents\n",
    "\n",
    "### 🏗️ Complete System Architecture Evolution\n",
    "\n",
    "```\n",
    "LEVEL 1: Basic Agent\n",
    "┌─────────────────┐\n",
    "│   BaseAgent     │\n",
    "│ LLM+Instructions│\n",
    "└─────────────────┘\n",
    "         ↓\n",
    "\n",
    "LEVEL 2: Specialized Agents\n",
    "┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐\n",
    "│ FactExtractor   │ │SentimentAnalyzer│ │   Summarizer    │\n",
    "│                 │ │                 │ │                 │\n",
    "└─────────────────┘ └─────────────────┘ └─────────────────┘\n",
    "         ↓\n",
    "\n",
    "LEVEL 3: Structured Output Agents\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Advanced Agents with JSON Output + Error Handling          │\n",
    "│  ┌──────────────────┐ ┌──────────────────────┐              │\n",
    "│  │FactExtractorAgent│ │SentimentAnalyzerAgent│              │\n",
    "│  │  → JSON Output   │ │  → JSON Output       │              │\n",
    "│  └──────────────────┘ └──────────────────────┘              │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "         ↓\n",
    "\n",
    "LEVEL 4: Tool-Enabled Agents\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│              Agents + External Tools                        │\n",
    "│  ┌─────────────────────────────────────────────────────┐    │\n",
    "│  │               ToolRegistry                          │    │\n",
    "│  │  ┌─────────────────┐ ┌──────────────────┐           │    │\n",
    "│  │  │  web_search()   │ │wikipedia_search()│           │    │\n",
    "│  │  └─────────────────┘ └──────────────────┘           │    │\n",
    "│  └─────────────────────────────────────────────────────┘    │\n",
    "│                              │                              │\n",
    "│  ┌─────────────────────────────────────────────────────┐    │\n",
    "│  │  FactExtractorAgentToolsEnabled                     │    │\n",
    "│  │  SentimentAnalyzerAgentToolsEnabled                 │    │\n",
    "│  │  → DECIDE → EXECUTE → SYNTHESIZE                    │    │\n",
    "│  └─────────────────────────────────────────────────────┘    │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "         ↓\n",
    "\n",
    "LEVEL 5: Multi-Agent Orchestration\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                    ORCHESTRATOR                             │\n",
    "│  ┌─────────────────────────────────────────────────────┐    │\n",
    "│  │  User Request Analysis & Agent Delegation           │    │\n",
    "│  └─────────────────────────────────────────────────────┘    │\n",
    "│                              │                              │\n",
    "│  ┌─────────────────────┐    ┌──────────────────────┐        │\n",
    "│  │ FactExtractorAgent  │    │SentimentAnalyzerAgent│        │\n",
    "│  │   (Tools Enabled)   │    │   (Tools Enabled)    │        │\n",
    "│  └─────────────────────┘    └──────────────────────┘        │\n",
    "│                              │                              │\n",
    "│  ┌─────────────────────────────────────────────────────┐    │\n",
    "│  │           Integrated Response                       │    │\n",
    "│  └─────────────────────────────────────────────────────┘    │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "\n",
    "FROM SIMPLE AGENTS → SOPHISTICATED MULTI-AGENT SYSTEM\n",
    "```\n",
    "\n",
    "### Architecture Patterns:\n",
    "\n",
    "- **BaseAgent**: Foundation for all agents\n",
    "- **ToolRegistry**: Centralized tool management\n",
    "- **Three-Step Tool Usage**: Decide → Execute → Synthesize\n",
    "- **Orchestrator Pattern**: Meta-agent for coordination\n",
    "\n",
    "### Real-World Applications:\n",
    "\n",
    "- **Customer Service**: Different agents for different types of inquiries\n",
    "- **Content Analysis**: Fact-checking, sentiment analysis, summarization\n",
    "- **Research Assistant**: Information gathering and synthesis\n",
    "- **Decision Support**: Multi-perspective analysis of complex problems\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Add More Tools**: Database access, APIs, file processing\n",
    "2. **Implement Memory**: Let agents remember previous interactions\n",
    "3. **Add Validation**: Error checking and response quality assurance\n",
    "4. **Scale Up**: Handle multiple users and concurrent requests\n",
    "5. **Specialized Domains**: Create agents for specific industries or use cases\n",
    "\n",
    "### Best Practices Learned:\n",
    "\n",
    "- **Clear Instructions**: Specific prompts lead to better results\n",
    "- **Structured Output**: JSON makes agents more useful\n",
    "- **Error Handling**: Always plan for failures\n",
    "- **Modular Design**: Keep agents focused on specific tasks\n",
    "- **Tool Integration**: External capabilities multiply agent power\n",
    "\n",
    "You now have the foundation to build sophisticated LLM agent systems for any domain!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
